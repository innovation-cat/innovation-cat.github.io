---
title: 'Blog Post number 1'
date: 2012-08-14
permalink: /posts/2012/08/blog-post-1/
tags:
  - cool posts
  - category1
  - category2
---

Diffusion models have been shown to be a highly promising approach in the field of image generation. They treat image synthesis as two independent processes: the forward process, which transforms a complex data distribution into a known prior distribution (typically a standard normal distribution) by gradually injecting noise; and the reverse process, which transforms the prior distribution back into the complex data distribution by gradually removing the noise.

---

## The unified forward process --- from a discrete perspective

We assume that the data distribution is $p_{data}$, while the prior distribution is $p_{init}$. For any time step $t$, the noised image $x_t$ can be obtained by adding noise $\varepsilon$ ( $\varepsilon \sim p_{init}$)   to an real image $x_0$ ( $x_0 \sim p_{data}$). We can formalize it as the following formula:

$$
x_t=s(t)*x_0+\sigma(t)*\varepsilon
$$

Where $s(t)$ represents the signal coefficient and $\sigma(t)$ represents the noise coefficient. The two mainstream types of noise schedules are Variance Preserving (VP) and Variance Exploding (VE).

**VPï¼š** Variance Preserving 
------