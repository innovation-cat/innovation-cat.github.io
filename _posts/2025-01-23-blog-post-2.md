---
title: 'Analysis of the Stability of Diffusion Model Training'
excerpt: "while diffusion models have revolutionized generative AI, their training challenges stem from a combination of resource intensity, optimization intricacies, and deployment hurdles. A stable training process ensures that the model produces good quality samples and converges efficiently over time without suffering from numerical instabilities."
date: 2025-01-23
permalink: /posts/2025/01/diffusion-model-2/
tags:
  - Diffusion Model
  - SNR
  - Model Training
---

<details style="background:#f6f8fa; border:1px solid #e5e7eb; border-radius:10px; padding:.6rem .9rem; margin:1rem 0;">
  <summary style="margin:-.6rem -.9rem .4rem; padding:.6rem .9rem; border-bottom:1px solid #e5e7eb; cursor:pointer; font-weight:600;">
    <span style="font-size:1.25em;"><strong>ğŸ“š Table of Contents</strong></span>
  </summary>
  <ul style="margin:0; padding-left:1.1rem;">
    <li><a href="#section1">Brief recap</a>
		<ul>
		  <li><a href="#section1.1">From Maximum likelihood to ELBO</a></li>
		  <li><a href="#section1.2">From KL collapses to a mean MSE</a></li>
		</ul>
	</li>
    <li><a href="#section2">Re-parameterising the mean with different target predictor</a>
		<ul>
		  <li><a href="#section2.1">x<sub>0</sub>-prediction</a></li>
		  <li><a href="#section2.2">&epsilon;-prediction</a></li>
		  <li><a href="#section2.3">v-prediction</a></li>
		  <li><a href="#section2.4">Score-prediction</a></li>
		</ul>
	</li>
	<li><a href="#section3">Imbalances in Learning Across Timesteps and SNR Regimes</a>
		<ul>
			<li><a href="#section3.1">A unifying lens: the $(x_0,\epsilon)$ basis and SNR</a></li>
			<li><a href="#section3.2">Root Causes of Differences</a>
			  <ul>
				  <li><a href="#section3.2.1">1) Correlation: Measuring Task Difficulty</a></li>
				  <li><a href="#section3.2.2">2) Conditional Expectation: Measuring Optimization Signal Strength</a></li>
				  <li><a href="#section3.2.3">3) Conditional Variance: Linking to Gradient Energy</a></li>
			  </ul>
			</li>
		</ul>
	</li>	
	<li><a href="#section4">Amplification of Network Prediction Errors Over Timesteps</a></li>
	<li><a href="#section5">Conclusion</a></li>
	<li><a href="#section6">References</a></li>
  </ul>
</details>



Diffusion models have achieved unprecedented success in the field of generative modeling, producing incredibly high-fidelity images, audio, and other data. However, the training process of these models presents several unique challenges like divergence, vanishing gradients, or unstable training behavior during the learning process. A stable training process ensures that the model produces good quality samples and converges efficiently over time without suffering from numerical instabilities.

In [previous post](https://innovation-cat.github.io/posts/2024/11/diffusion-model-1/), we review the basic concepts of diffusion model, this post we will focus on training. 

&nbsp;

# <a id="section1">Brief recap</a>

For generative models, we expect our model $p_{\theta}$ (parameterized by $\theta$) to be as close as possible to the true distribution $p_{data}$. Based on the KL divergence, we derive that

$$
\mathbb{KL}(p_{data}(x) \parallel p_{\theta}(x)) = \int p_{data}(x)\log (p_{data}(x))dx - \int p_{data}(x)\log(p_{\theta}(x))dx\label{eq:1}
$$

The first term, $\int p_{data}(x) \log (p_{data}(x))dx$, is the entropy of the true distribution
$p_{data}$, it is a constant with respect to the model parameters $\theta$. The second term, $\int p_{data}(x)\log(p_{\theta}(x))dx$, is the expected log-likelihood of the model under the true distribution. Thus, minimizing KL divergence is equal to maximize log-likelihood $p_{\theta}(x)$, where $x \sim p_{data}$.

## <a id="section1.1">From Maximum likelihood to ELBO</a>

Let $x_0$ be the original image, and $x_i (i=1,2,...,T)$ be the image with noise added to $x_0$. We wish to maximise 

$$
\log p_{\theta}(x_0)=\log \int p_{\theta}(x_{0:T}) dx_{1:T} \label{eq:2}
$$

Introduce the forward process $q(x_{1:T} \mid x_0)$ (a Markov chain with fixed noiseâ€‘schedule). Using Jensenâ€™s inequality gives the evidence lower bound:

$$
\begin{align}
\log p_\theta(x_0) \geq \mathcal{L}_\text{ELBO} & = \mathbb{E}_q \left[ \log p_\theta(x_0 \mid x_1) - \log \frac{q(x_{T} \mid x_0)}{p_\theta(x_{T})} - \sum_{t=2}^T \log \frac{q(x_{t-1} \mid x_t, x_0)}{p_\theta(x_{t-1} \mid x_t)} \right]\label{eq:3}
\end{align}
$$

The first term is reconstruction loss, the second term is prior matching, both of them are extremely small and can be ignored. Therefore, what we are truly concerned about is the third item, which also known as denoising term.


## <a id="section1.2">From KL collapses to a mean MSE</a>

For each denoising step, both forward posterior $q(x_{t-1} \mid x_t, x_0) \sim \mathcal{N}(\mu_{q}, \sigma_{q}^2I)$ and backward posterior
$p_{\theta}(x_{t-1} \mid x_t) \sim \mathcal{N}(\mu_{\theta}, \sigma_{\theta}^2I)$ are gaussian distributions. For two Gaussians with identical covariance, if we fix the two variances are equal to $\sigma_{q}^2$, then the KL divergence is equal to:

$$
\mathbb{KL}\left(q(x_{t-1} \mid x_t, x_0) \parallel p_{\theta}(x_{t-1} \mid x_t) \right) = \frac{1}{2\sigma_q^2} \|{\mu}_{q} - \mu_{\theta}(x_t, t)\|_2^2 + \text{const}\label{eq:4}
$$

Hence, for each denoising step, the loss function equals to

$$
\mathcal{L}_{\text{denoise}} =  \mathbb{E}_q \left[ \|\mu_q - \mu_{\theta}(x_t, t)\|^2 \right]\label{eq:5} 
$$

$\mu_q$ is the true target we want to predict, How do we calculate the value of 
$\mu_q$? Let's first decompose forward posterior $q(x_{t-1} \mid x_t, x_0)$ :

$$
q(x_{t-1} \mid x_t, x_0)=\frac{q(x_{t} \mid x_{t-1})q(x_{t-1} \mid x_{0})}{q(x_{t} \mid x_{0})} \propto q(x_{t} \mid x_{t-1})q(x_{t-1} \mid x_{0})\label{eq:6}
$$

where 

$$
q(x_{t} \mid x_{t-1}) \sim \mathcal{N}(x_{t-1};\mu_1, \sigma_1^2I),\ \ \mu_1=\frac{1}{\sqrt{\alpha_t}}x_{t},\ \ \sigma_1^2=\frac{1-\alpha_t}{\alpha_t} \\[10pt] q(x_{t-1} \mid x_{0})  \sim \mathcal{N}(x_{t-1};\mu_2, \sigma_2^2I), \ \ \mu_2=\sqrt{\bar \alpha_{t-1}}x_{0},\ \  \sigma_2^2=1-\bar \alpha_{t-1}\label{eq:7}
$$

The product of two Gaussian distributions is itself a Gaussian distribution, 




$$
\mu_{q} = \frac{\mu_1\sigma_2^2+\mu_2\sigma_1^2}{\sigma_1^2+\sigma_2^2}  = \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1 - \alpha_t) {x}_0}{1 - \bar{\alpha}_t}\label{eq:8}
$$

Combining equations \ref{eq:5} and \ref{eq:8}, Our goal is to construct a neural network $\mu_{\theta}$, which takes $x_t$ and $t$ as inputs, such that the output of the network is as close as possible to $\mu_q$.


--- 

# <a id="section2">Re-parameterising the mean with different target predictor</a>

Following equation \ref{eq:8}, we can dirrectly build a network $\mu_{\theta}$ to output $\mu_{q}$. However, in practice, we usually do not directly fit the value of $\mu_{q}$, mainly due to the following reasons.

- $\mu_{q}$ is an affine function of $x_t$, which is known at training and test time, there is no need for the network to â€œreproduceâ€ it. If we regress $\mu_{q}$ directly, the network wastes capacity relearning a large known term and must also learn the residual that actually depends on the unknown clean content. 

- The mean target value is highly time-dependent scaling across $t$, which means that the output of the network is unstable, it is usually extremely difficult for a network to output results with a large variance range.


Instead of asking the network to output $\mu_{q}$ directly, the community typically uses four common prediction targets to train diffusion models: $\epsilon$-prediction, $x_0$-prediction, $v$-prediction, score-prediction. If we regard the original image $x_0$ and noise $\epsilon$ as two orthogonal dimensions, then All the common targets are linear in $(x_0, \epsilon)$


## <a id="section2.1">$x_0$-prediction (aka sample-prediction in Diffusers)</a>

In $x_0$-prediction, the neural network is trained to directly estimate the clean original data $x_0$ from the noisy input $x_t$ at timestep $t$. Denoted the network as $ x_{\theta}(x_t, t)$, and the predicted output is $$\hat{x}_0$$, this approach reparameterizes the predicted mean $\mu_{\theta}$ using the estimated $$\hat{x}_0$$. Substituting into Equation \ref{eq:8}, the mean becomes:

$$
\mu_{\theta}(x_t, t) = \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1 - \alpha_t) \hat{x}_0}{1 - \bar{\alpha}_t}\label{eq:9}
$$

The loss function then simplifies to minimizing the MSE between the true $x_0$ and the predicted $\hat{x}_0$:

$$
\mathcal{L} = \mathbb{E}_{x_0, t, \epsilon} \left[ \| x_0 - x_{\theta}(x_t, t) \|^2 \right]\label{eq:10}
$$

**Pros**

This parameterization is advantageous because the target $x_0$ has a consistent scale across timesteps, reducing the variance in network outputs and improving training stability. 

**Cons**

The primary drawback of $x_0$-prediction lies in the uneven learning difficulty across signal-to-noise ratio (SNR) regimes, which induces heterogeneous gradient behaviors and ultimately hinders training convergence. 


## <a id="section2.2">$\epsilon$-prediction</a>

The $\epsilon$-prediction paradigm tasks the network with predicting the noise $\epsilon$ added during the forward process. This parameterization leverages the forward noising equation to express the clean data $x_0$ in terms of the noise $\epsilon$ via a simple linear transformation (equation \ref{eq:11}). 

$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon \  \Longrightarrow \  x_0=\frac{x_t-\sqrt{1 - \bar{\alpha}_t} \epsilon}{\sqrt{\bar{\alpha}_t}}\label{eq:11}
$$ 

Substituting this reparameterized form of $x_0$ (with $\hat{\epsilon}$ in place of $\epsilon$) into Equation \ref{eq:8} for the mean gives:

$$
\mu_{\theta}(x_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \hat{\epsilon} \right)\label{eq:12}
$$

The loss function then simplifies to minimizing the MSE between the true noise $\epsilon$ and the predicted $\hat{\epsilon}$:

$$
\mathcal{L} = \mathbb{E}_{x_0, t, \epsilon} \left[ \| \epsilon - \epsilon_{\theta}(x_t, t) \|^2 \right]\label{eq:13}
$$

**Pros**

This parameterization is advantageous because the target $\epsilon$ is timestep-independent target distribution since $\epsilon \sim \mathcal{N}(0, I)$.

**Cons**

Like $x_0$-prediction, $\epsilon$-prediction also suffers from the uneven learning difficulty problems, which needs re-weighting $ w(t) $ to promote balanced learning across the noise spectrum. We will conduct more in-depth analysis in the following sections.



## <a id="section2.3">$v$-prediction</a>

Velocity ($v$)-prediction combines elements of both $x_0$ and $\epsilon$ predictions by forecasting a velocity term $v$ that interpolates between them. Defined velocity as $$v = \sqrt{\bar{\alpha}_t} \epsilon - \sqrt{1 - \bar{\alpha}_t} x_0$$ (or its normalized variant), the network predicts $$\hat{v} = v_{\theta}(x_t, t)$$. The mean $\mu_{\theta}$ can be expressed in terms of $$\hat{v}$$:

$$
\mu_{\theta}(x_t, t) = \sqrt{\alpha_t}x_t- \frac{(1-\alpha_t)\sqrt{\bar \alpha_{t-1}}}{\sqrt{1-\bar \alpha_t}}{\hat v}\label{eq:14}
$$

The loss function then simplifies to minimizing the MSE between the true velocity $v$ and the predicted $$\hat{v}$$:

$$
\mathcal{L} = \mathbb{E}_{x_0, t, \epsilon} \left[ \| v - v_{\theta}(x_t, t) \|^2 \right]\label{eq:15}
$$

This hybrid approach adapts dynamically to timestep: in high SNR regimes, it behaves like $\epsilon$-prediction, while in low SNR regimes, it resembles $x_0$-prediction. This adaptability enhances stability by balancing gradient flows across SNR levels, reducing divergence risks, but requires precise calibration of the velocity formulation to avoid numerical instabilities during backpropagation.


## <a id="section2.4">Score-prediction</a>

This parameterization draws from the score-based generative modeling framework, where the neural network estimates the score function $s_{\theta}(x_t, t) = \nabla_{x_t} \log p_t(x_t)$, representing the gradient of the log-probability density at the noisy state $x_t$. In Gaussian diffusion models, the score is directly related to the noise via $$s(x_t, t) = -\frac{\epsilon}{\sqrt{1 - \bar \alpha_t}}$$, allowing a re-expression of the noise $\epsilon$ in terms of the score. Starting from the forward noising equation and substituting the equivalent form $$\epsilon = -\sqrt{1 - \bar{\alpha}_t} \, s(x_t, t)$$, the predicted mean $$\mu_{\theta}$$ is derived by inserting this into Equation \ref{eq:8}:

$$
\mu_{\theta}(x_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( x_t + (1 - \alpha_t) \, s_{\theta}(x_t, t) \right)
$$

The loss function simplifies to minimizing the MSE between the true score $s(x_t, t)$ and the predicted $$\hat{s} = s_{\theta}(x_t, t)$$:

$$\mathcal{L} = \mathbb{E}_{x_0, t, \epsilon} \left[ \| s(x_t, t) - s_{\theta}(x_t, t) \|^2 \right]$$

**Pros**
Integrated in models like Score-Based Generative Models (SGMs) and aligned with continuous-time formulations, this approach facilitates theoretical connections to stochastic differential equations (SDEs) and enhances generalization across noise schedules. 

**Cons**
However, it may introduce scaling sensitivities in discrete timesteps, potentially leading to instabilities if the score magnitudes are not properly normalized, necessitating adaptive weighting or variance adjustments during training. In general, it has more theoretical value but is rarely used in practice.


---

# <a id="section3">Imbalances in Learning Across Timesteps and SNR Regimes</a>

Diffusion training looks deceptively simple: draw a noisy pair $(x_0, x_t)$ from the forward process and regress a target $y_t$ with an MSE. Although the four targets â€” $\epsilon$-prediction, $x_0$-prediction, $v$-prediction, and score-prediction â€” are linearly transformable, in practice, **which target** you regress mattersâ€”a lot. Different targets place learning pressure on **different SNR bands**, change the **numerical conditioning** of the regression, and interact differently with **weighting/preconditioning** and the **sampler** youâ€™ll use at test time. This section builds a unified, quantitative picture of *why* these differences arise and *how* to correct them.


 they exhibit **uneven learning difficulty** under unit weights $w(t)\equiv 1$. Using **SNR** rather than the raw timestep $t$ reveals these imbalances clearly.


## <a id="section3.1">A unifying lens: the $(x_0,\epsilon)$ basis and SNR</a>


Forward noising:

$$
x_t \;=\; a\,x_0 + b\,\epsilon,\qquad a=\sqrt{\bar\alpha_t},\; b=\sqrt{1-\bar\alpha_t},\quad \epsilon\sim\mathcal N(0,I).
$$

Define the **signal-to-noise ratio** (SNR):

$$
\mathrm{SNR}(t)\;=\;\frac{a^2}{b^2}\;=\;\frac{\bar\alpha_t}{1-\bar\alpha_t}
$$

- **High SNR** $\Rightarrow$ early timesteps (signal-dominated; easier).  
- **Low SNR** $\Rightarrow$ late timesteps (noise-dominated; harder).

Any target used in practice is a *linear functional* of $(x_0,\epsilon)$. The common four are
- **$\epsilon$-prediction:** $y_t=\epsilon$
- **$x_0$-prediction:** $y_t=x_0$
- **$v$-prediction:** $y_t=v := a\,\epsilon - b\,x_0$  (an orthogonalized combo)
- **score-prediction:** $y_t=s(x_t,t)= -\dfrac{x_t-a x_0}{b^2}= -\dfrac{\epsilon}{b}$ (conditional score of $q(x_t\|x_0)$)

They are *linearly equivalent* (you can recover one from another), but that does **not** mean they have the same **learning dynamics** under the same loss and weights.


## <a id="section3.2">Root Causes of Differences (Unified View: Correlation â†’ Conditional Expectation â†’ Gradient)</a>

It is well established that the four common training targets in diffusion models â€” $\epsilon$-prediction, $x_0$-prediction, $v$-prediction, and score-prediction â€”  can all be expressed under a unified mean-squared error (MSE) loss formulation:

$$
\ell(\theta; x_t, y_t) = \|\, y_t - f_{\theta}(x_t, t) \,\|^2\label{eq:20}
$$

where $y_t$ is the chosen target, and $f_{\theta}(x_t, t)$ is the model output given $x_t$ and timestep $t$. Although these targets are linearly interconvertible, empirical results show substantial differences in training dynamics and final performance depending on the target choice.

A theoretically grounded explanation can be formulated in terms of three quantities:

1. **Correlation coefficient (or optimal linear slope)** â€” quantifies **task difficulty** under a linear predictability assumption.
2. **Conditional expectation** â€” quantifies **gradient signal strength**.
3. **Conditional variance** â€” quantifies **gradient stability**.

---

### Unified Derivation

Let the training loss be:

$$
\ell(\theta; x_t, y_t) = \frac12 \|\, y_t - f_{\theta}(x_t, t) \,\|^2, \quad L(\theta) = \mathbb{E}[\ell]
$$

- Bayes-optimal predictor: For fixed $(x_t, t)$, the risk-minimizing predictor is:

  $$
  f^{\star}(x_t, t) = \mathbb{E}[\,y_t \mid x_t, t\,]
  $$

- Variance decomposition: The MSE admits the decomposition:

$$
\mathbb{E}\!\left[\|y - f_{\theta}\|^2\right]
= \underbrace{\mathbb{E}\!\left[\|\mu - f_{\theta}\|^2\right]}_{\text{Reducible error}}
+ \underbrace{\mathbb{E}\!\left[\mathrm{Tr}\,\mathrm{Var}(y \mid x_t, t)\right]}_{\text{Irreducible noise}}.
$$

- Gradient structure: The gradient of the per-sample loss w.r.t. the model parameters is:

$$
\frac{\partial \ell}{\partial f_{\theta}} = f_{\theta} - y,
$$

$$
\nabla_{\theta} \ell = (f_{\theta} - y)\, J_{\theta}, \quad J_{\theta} := \frac{\partial f_{\theta}}{\partial \theta}.
$$

Conditioned on $(x_t, t)$:

$$
\mathbb{E}[\nabla_{\theta} \ell \mid x_t, t] = \big(f_{\theta} - \mu(x_t, t)\big)\, J_{\theta},
$$

$$
\mathrm{Cov}[\nabla_{\theta} \ell \mid x_t, t] = J_{\theta}^\top \,\mathrm{Var}(y \mid x_t, t)\, J_{\theta}.
$$

Thus:

- The **magnitude of the conditional mean** $\|\mu(x_t, t)\|$ determines the **gradient signal strength**, particularly in the early training stage when $f_{\theta} \approx 0$.
- The **conditional variance** $\mathrm{Var}(y \mid x_t, t)$ determines the **variance of the gradient noise**, i.e., the stability of the updates.

#### Gradient signal-to-noise ratio (GSNR)
A natural measure of learning difficulty at timestep $t$ is the **gradient signal-to-noise ratio**:
$$
\mathrm{GSNR}(x_t, t) := \frac{\|\mathbb{E}[\nabla_{\theta} \ell \mid x_t, t]\|^2}{\mathrm{Tr}\,\mathrm{Cov}[\nabla_{\theta} \ell \mid x_t, t]}
\ \overset{f_{\theta} \approx 0}{\approx}\
\frac{\|\mu(x_t, t)\|^2}{\mathrm{Tr}\,\mathrm{Var}(y \mid x_t, t)}.
$$
The numerator represents the deterministic component of the gradient (signal), and the denominator the stochastic component (noise).

---

### <a id="section3.2.1">1) Correlation: Measuring Task Difficulty</a>

For a target $y_t$ (which can be $\epsilon$, $x_0$, $v$, or $s=\nabla_{x_t} \log p_t$), we compute its Pearson correlation with $x_t$ at different SNR levels:

$$\rho_t = \dfrac{\mathrm{Cov}(y_t,x_t)}{\sqrt{\mathrm{Var}(y_t)\mathrm{Var}(x_t)}}$$

A higher correlation implies that $y_t$ can be well approximated as a linear function of $x_t$, making the prediction task easier.

- $\epsilon$-prediction: $\rho_{\epsilon, x_t} = \dfrac{1}{\sqrt{1+\mathrm{SNR}}}$ â€” **strong at low SNR, weak at high SNR**, easiest to learn in low-SNR regions but harder in high-SNR regions.
- $x_0$-prediction: $\rho_{x_0, x_t} = \sqrt{\dfrac{\mathrm{SNR}}{1+\mathrm{SNR}}}$ â€” **strong at high SNR, weak at low SNR**, easiest to learn in high-SNR regions but harder in low-SNR regions.
- $v$-prediction: $\rho_{v, x_t} = 0$ â€” orthogonal to $x_t$ for all SNR, tends to maintain a more balanced correlation across SNR, indicating more uniform difficulty.
- score-prediction: $\rho_{s, x_t} = -\dfrac{1}{\sqrt{1+\mathrm{SNR}}}$ â€” same magnitude as $\epsilon$ but opposite sign.

The following figure shows Pearson correlation between four target values and $x_t$, with the horizontal axis corresponding to SNR and T respectively.

![Correlation vs SNR and t](/images/posts/post_2/correlation.png)

---

### <a id="section3.2.2">2) Conditional Expectation: Measuring Optimization Signal Strength</a>

A fundamental principle of statistics states that to minimize the loss function (equation \ref{eq:20}), the optimal model $f_{\theta}^{\star}$ must predict the conditional expectation of the target y given the input $x_t$, i,e., $f_{\theta}^{\star} = \mathbb{E}(y \mid x_t)$. To understand why one target $y$ is better than another, we must analyze the properties of its conditional mean.

We start from the forward diffusion process equation: $x_t = a_t x_0 + b_t \epsilon$, taking the conditional expectation with respect to $ x_t $ on both sides (noting that $ E(x_t \| x_t) = x_t $, and using linearity of expectation):

$$
E(x_t | x_t) = a_t E(x_0 | x_t) + b_t E(\epsilon | x_t) \Longrightarrow x_t = a_t E(x_0 | x_t) + b_t E(\epsilon | x_t) 
$$

---

### <a id="section3.2.3">3) Conditional Variance: Linking to Gradient Energy</a>

Near the optimum, the sample gradient of the MSE loss is $2(\hat{y}_t - y_t)$.  
With $\hat{y}_t \approx \mathbb{E}[y_t \mid x_t]$, the gradient variance is dominated by the **irreducible noise**:
$$
\mathbb{E}\,\|\nabla_\theta \mathcal{L}_t\|^2 \;\propto\; \mathrm{Var}(y_t \mid x_t).
$$

Per target:
- $\epsilon$: $\dfrac{\mathrm{SNR}}{1+\mathrm{SNR}}$  
- $x_0$: $\dfrac{1}{1+\mathrm{SNR}}$  
- $v$: $1$  
- score: $\mathrm{SNR}$

Implications without any re-weighting:
- $\epsilon$: large gradient energy at **high SNR**, small at **low SNR**.  
- $x_0$: the opposite trend.  
- $v$: equal gradient energy across SNR.  
- score: gradient energy grows with SNR, potentially unstable in high-SNR regimes.

**Figure 3: Conditional variance vs SNR (four targets)**  
![Conditional variance vs SNR](/images/posts/post_2/condvar_vs_snr_fusion.png)

---

**Summary**  
Learning imbalance arises from two factors:  
1) how *predictability* ($\rho$, $k_y$) varies across SNR, and  
2) how *noise-driven gradient energy* $\mathrm{Var}(y_t \mid x_t)$ is distributed over timesteps.  

SNR-aware weighting strategies (e.g., P2, min-SNR, EDM) directly reshape these profiles, yielding more stable and efficient training.


---
### 2. Multi-Metric Comparison under **Unit Weights**

Let $a=\sqrt{\bar\alpha_t}$, $b=\sqrt{1-\bar\alpha_t}$, so $\mathrm{SNR}=\dfrac{a^2}{b^2}$ and $x_t=a\,x_0+b\,\epsilon$. We consider four targets:
- $\epsilon$-prediction;
- $x_0$-prediction;
- $v=a\,\epsilon-b\,x_0$;
- **score** $s(x_t,t)=-\dfrac{x_t-a\,x_0}{1-a^2}=-\dfrac{\epsilon}{b}$.

#### 2.1 Metrics, Formulas, and Rationale

| Metric | Definition | Why it Matters |
|---|---|---|
| **Correlation** $\rho(y_t,x_t)$ | $\dfrac{\mathrm{Cov}(y_t,x_t)}{\sqrt{\mathrm{Var}(y_t)\mathrm{Var}(x_t)}}$ | Linear predictability; $\rho^2$ equals $R^2$. |
| **Bayes Error** | $\mathrm{Var}(y_t\mid x_t)$ | Irreducible noise of the regression target. |
| **Gradient Scale** $G$ | $\propto \sqrt{\mathrm{Var}(y_t\mid x_t)}$ | Proxy for SGD magnitude per SNR. |
| **Mutual Information** | $-\tfrac12\log(1-\rho^2)$ | Info-theoretic predictability (nats). |
| **Predictability Ratio** $\Pi$ | $\dfrac{\mathrm{Var}(\mathbb E[y_t\mid x_t])}{\mathrm{Var}(y_t\mid x_t)}$ | Signal-to-noise ratio of the target. |
| **Bayes Slope** $k_y$ | $\mathrm{Cov}(y_t,x_t)$ | Gain of the Bayes regressor; matters for conditioning. |
| **Unconditional Var** | $\mathrm{Var}(y_t)$ | Target scale (can destabilize training if large). |
| **Preconditioning Factor** $g_y$ | $1/\sqrt{\mathrm{Var}(y_t\mid x_t)}$ | Output scaling that flattens gradient scale. |

#### 2.2 Closed-Form Results (Unit Weights)

- **Correlation**:
  - $\epsilon$: $\rho=\dfrac{1}{\sqrt{1+\mathrm{SNR}}}$; 
  - $x_0$: $\rho=\sqrt{\dfrac{\mathrm{SNR}}{1+\mathrm{SNR}}}$; 
  - $v$: $\rho=0$; 
  - score: $\rho=-\dfrac{1}{\sqrt{1+\mathrm{SNR}}}$.

- **Bayes Error** $\mathrm{Var}(y\mid x_t)$:
  - $\epsilon$: $\dfrac{\mathrm{SNR}}{1+\mathrm{SNR}}$; 
  - $x_0$: $\dfrac{1}{1+\mathrm{SNR}}$; 
  - $v$: $1$; 
  - score: $\mathrm{SNR}$.

- **Gradient Scale** $G\propto \sqrt{\mathrm{Var}(y\mid x_t)}$:
  - $\epsilon$: $\sqrt{\dfrac{\mathrm{SNR}}{1+\mathrm{SNR}}}$;
  - $x_0$: $\dfrac{1}{\sqrt{1+\mathrm{SNR}}}$;
  - $v$: $1$ (flat);
  - score: $\sqrt{\mathrm{SNR}}$.

- **Mutual Information** (nats): 
  - $\epsilon$: $\tfrac12\log(1+\tfrac{1}{\mathrm{SNR}})$; 
  - $x_0$: $\tfrac12\log(1+\mathrm{SNR})$; 
  - $v$: $0$; 
  - score: same as $\epsilon$.

- **Predictability Ratio** $\Pi$:
  - $\epsilon$: $\tfrac{1}{\mathrm{SNR}}$; 
  - $x_0$: $\mathrm{SNR}$; 
  - $v$: $0$; 
  - score: $\tfrac{1}{\mathrm{SNR}}$.

- **Bayes Slope** $k_y$:
  - $\epsilon$: $\dfrac{1}{\sqrt{1+\mathrm{SNR}}}$; 
  - $x_0$: $\sqrt{\dfrac{\mathrm{SNR}}{1+\mathrm{SNR}}}$; 
  - $v$: $0$; 
  - score: $-1$.

- **Unconditional Var** $\mathrm{Var}(y)$:
  - $\epsilon$: $1$; $x_0$: $1$; $v$: $1$; score: $1+\mathrm{SNR}$.

- **Preconditioning** $g_y\propto 1/\sqrt{\mathrm{Var}(y\mid x_t)}$:
  - $\epsilon$: $\sqrt{\dfrac{1+\mathrm{SNR}}{\mathrm{SNR}}}$; 
  - $x_0$: $\sqrt{1+\mathrm{SNR}}$; 
  - $v$: $1$; 
  - score: $\mathrm{SNR}^{-1/2}$.

**Baseline curvesï¼ˆunit weightsï¼‰**  
ï¼ˆè¿™äº›å›¾å·²åœ¨ä¸Šä¸€å°èŠ‚ç»™å‡ºï¼Œè·¯å¾„è¯·æŒ‰ä½ ä»“åº“æ›¿æ¢ï¼‰
- Correlation vs SNR: `.../correlation_vs_snr.png`  
- Gradient scale vs SNR: `.../gradscale_vs_snr.png`  
- Predictability Ratio: `.../predictability_ratio_vs_snr.png`  
- Mutual Information: `.../mutual_information_vs_snr.png`  
- Bayes Error: `.../bayes_error_vs_snr.png`  
- Bayes Slope: `.../bayes_regressor_slope_vs_snr.png`  
- Target Variance: `.../target_variance_vs_snr.png`  
- Preconditioning Factor: `.../preconditioning_vs_snr.png`

---

### 3. SOTA Weighting & Preconditioning: What They Do and How They Look

We summarize practical **SOTA** schemes and visualize **before vs after** on key targets using the **gradient-scale** proxy (the metric most immediately affected by weighting/target scaling).  
> æ³¨ï¼šç›¸å…³æ€§ä¸ Bayes error ç”±æ•°æ®ç”Ÿæˆè¿‡ç¨‹å†³å®šï¼Œä¸éšæŸå¤±æƒé‡æ”¹å˜ï¼›å› æ­¤ä¸»è¦æ¯”è¾ƒ**æ¢¯åº¦å°ºåº¦**çš„å†åˆ†é…æ•ˆæœã€‚

#### 3.1 p2-weighting (perception-prioritized)
A common form:
$$
w_{\mathrm{p2}}(t)\propto (\mathrm{SNR}(t)+c)^{-\gamma},\;\; \gamma>0,\; c\in[0,1].
$$
- **ä½œç”¨**ï¼šæŠ‘åˆ¶é«˜ SNRï¼ˆæ—©æœŸï¼‰æ­¥çš„æ¢¯åº¦ï¼Œè¡¥å¿ä¸­/ä½ SNRã€‚  
- **æ¨è**ï¼šæ­é… $\epsilon$-predictionã€‚

**epsilon: unit vs p2ï¼ˆç¤ºä¾‹å‚æ•° $\gamma\!=\!1,\,c\!=\!1$ï¼‰**  
![epsilon â€” unit vs p2](/assets/img/diffusion/epsilon_gradscale_unit_vs_p2.png)

#### 3.2 Min-SNR weighting / clipping
ç»™ $\mathrm{SNR}$ è®¾ç½®ä¸‹é™ $\tau$ å½¢æˆæƒé‡ï¼ˆå¸¸è§å®ç°ç­‰ä»·äºåœ¨ä½ SNR æ”¾å¤§æŸå¤±ï¼‰ï¼š
$$
\tilde{\mathrm{SNR}}(t)=\max(\mathrm{SNR}(t),\tau),\quad
w_{\min\text{-}SNR}(t)\approx \frac{\tilde{\mathrm{SNR}}(t)}{\mathrm{SNR}(t)}.
$$
- **ä½œç”¨**ï¼šé˜²æ­¢ä½ SNR åŒºåŸŸæ¢¯åº¦â€œé¥¿æ­»â€ï¼Œæ”¹å–„æœ«æœŸè¿˜åŸè´¨é‡ã€‚  
- **æ¨è**ï¼šå¸¸é…åˆ $x_0$-prediction æˆ– $v$-predictionã€‚

**x0: unit vs min-SNRï¼ˆç¤ºä¾‹ $\tau\!=\!10^{-1}$ï¼‰**  
![x0 â€” unit vs min-SNR](/assets/img/diffusion/x0_gradscale_unit_vs_minsnr.png)

#### 3.3 EDM-style preconditioning
åœ¨å™ªå£°æ°´å¹³ $\sigma^2=(1-\bar\alpha_t)/\bar\alpha_t=1/\mathrm{SNR}$ ç©ºé—´åšè¾“å…¥/è¾“å‡ºé¢„æ¡ä»¶å’Œæƒé‡ï¼ˆå…¸å‹ä¾‹ï¼š$w(\sigma)\!\propto\!1/(\sigma^2\!+\!1)$ï¼‰ï¼Œæ ¸å¿ƒç›®æ ‡æ˜¯è®©**æœ‰æ•ˆæ¢¯åº¦**åœ¨ $\log\sigma$ è½´ä¸Šè¶‹äº**å‡åŒ€**ã€‚  
- **ä½œç”¨**ï¼šé€šè¿‡**ç›®æ ‡ç¼©æ”¾**ä¸**è¾“å…¥æ ‡å‡†åŒ–**ï¼Œè¿‘ä¼¼å®ç° $g_y\cdot G(\mathrm{SNR})\approx \text{const}$ã€‚  
- **æ¨è**ï¼šå¯¹ $\epsilon$ ä¸ $x_0$ å°¤å…¶æœ‰æ•ˆï¼›å¯¹ $v$ å˜åŒ–å¾ˆå°ï¼ˆå…¶æœ¬å°±è¾ƒå¹³å¦ï¼‰ã€‚

**epsilon: unit vs EDM é¢„æ¡ä»¶ï¼ˆç¤ºæ„ä»¥ $g_\epsilon$ å®ç°ï¼‰**  
![epsilon â€” unit vs EDM](/assets/img/diffusion/epsilon_gradscale_unit_vs_edm.png)

**x0: unit vs EDM é¢„æ¡ä»¶ï¼ˆç¤ºæ„ä»¥ $g_{x_0}$ å®ç°ï¼‰**  
![x0 â€” unit vs EDM](/assets/img/diffusion/x0_gradscale_unit_vs_edm.png)

**score: unit vs EDM é¢„æ¡ä»¶ï¼ˆç¤ºæ„ä»¥ $g_{s}$ å®ç°ï¼‰**  
![score â€” unit vs EDM](/assets/img/diffusion/score_gradscale_unit_vs_edm.png)

**v: unit vs EDM é¢„æ¡ä»¶ï¼ˆå‡ ä¹æ— å˜åŒ–ï¼‰**  
![v â€” unit vs EDM](/assets/img/diffusion/v_gradscale_unit_vs_edm.png)

#### 3.4 Loss-aware / difficulty-aware weighting
æ ¹æ®**è¿‘æœŸæŸå¤±å¤§å°æˆ–æ¢¯åº¦æ–¹å·®**åŠ¨æ€è°ƒæ•´ $w(t)$ï¼ˆå¦‚ $w\!\leftarrow\!1/\mathrm{EMA}[\mathcal L_t]$ æˆ–æŒ‰ SNR åˆ†æ¡¶ä¼°è®¡æ–¹å·®ååæ¯”ç¼©æ”¾ï¼‰ã€‚  
- **ä½œç”¨**ï¼šè‡ªé€‚åº”èšç„¦â€œæœªå­¦å¥½â€çš„æ—¶é—´æ®µï¼Œå…¼å®¹ä»»æ„ç›®æ ‡ã€‚  
- **æ³¨æ„**ï¼šéœ€é˜²æ­¢è¿‡åº¦æŒ¯è¡ï¼Œå¼•å…¥å¹³æ»‘ä¸ä¸Š/ä¸‹ç•Œã€‚

---

### 4. Practical Reading

- **$\epsilon$-prediction**ï¼šåŸç”Ÿåå‘**é«˜ SNR**ï¼›ç”¨ **p2/EDM** æ‹‰å¹³ã€‚  
- **$x_0$-prediction**ï¼šåŸç”Ÿåå‘**ä½ SNR**ï¼›ç”¨ **min-SNR/EDM** è¡¥é½é«˜ SNRã€‚  
- **$v$-prediction**ï¼šæ¢¯åº¦è¿‘ä¹**å¹³å¦**ï¼›é€šå¸¸åªéœ€è½»é‡é¢„æ¡ä»¶æˆ–ç›´æ¥ç”¨ unit weightsã€‚  
- **score-prediction**ï¼šå°ºåº¦éš SNR å¢é•¿å¿«ï¼›éœ€**å¼ºé¢„æ¡ä»¶**ä¸/æˆ–ä¸Šç•Œæ§åˆ¶ã€‚

**Bottom line.** Multi-metric, SNR-indexed analysis shows **where** each target is imbalanced under unit weights and **how** modern reweighting/é¢„æ¡ä»¶ reshape gradient energy to be more uniform â€” improving stability and convergence speed without changing expressivity.


---

# <a id="section4">Amplification of Network Prediction Errors Over Timesteps</a>



---

# <a id="section5">Conclusion</a>

---

# <a id="section6">References</a>

[^iedm]: Karras T, Aittala M, Lehtinen J, et al. Analyzing and improving the training dynamics of diffusion models[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024: 24174-24184.

[^edm]: Karras T, Aittala M, Aila T, et al. Elucidating the design space of diffusion-based generative models[J]. Advances in neural information processing systems, 2022, 35: 26565-26577.

[^Kingma]: Kingma D, Gao R. Understanding diffusion objectives as the elbo with simple data augmentation[J]. Advances in Neural Information Processing Systems, 2023, 36: 65484-65516.

[^Salimans]: Salimans T, Ho J. Progressive distillation for fast sampling of diffusion models[J]. arXiv preprint arXiv:2202.00512, 2022.
